{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69edaba",
   "metadata": {},
   "source": [
    "\n",
    "## Convolution \n",
    "\n",
    "1. https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\n",
    "2. https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\n",
    "3. https://youtu.be/HGwBXDKFk9I\n",
    "\n",
    "\n",
    "## To setup torch env \n",
    "1. https://pytorch.org/get-started/locally/\n",
    "\n",
    "\n",
    "1. https://medium.com/@minions.k/optimization-techniques-popularly-used-in-deep-learning-3c219ec8e0cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ced459",
   "metadata": {},
   "source": [
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738b2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from fastprogress import progress_bar, master_bar\n",
    "import mlcrate.time as mlctime\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "timer = mlctime.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset downloaded from - https://www.kaggle.com/datasets/zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587408b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 785), (10000, 785))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../../input/fashionmnist/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"../../input/fashionmnist/fashion-mnist_test.csv\")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71eef74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4040c0",
   "metadata": {},
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c51f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_5_seed_42\n",
      "0    12000\n",
      "1    12000\n",
      "2    12000\n",
      "3    12000\n",
      "4    12000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5 # number of folds\n",
    "seed = 42 # seed to control randomness\n",
    "\n",
    "nFolds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(nFolds.split(X=train_df, y=train_df['label'])):\n",
    "    train_df.loc[val_index, f'fold_{n_folds}_seed_{seed}'] = int(n)\n",
    "\n",
    "train_df[f'fold_{n_folds}_seed_{seed}'] = train_df[f'fold_{n_folds}_seed_{seed}'].astype(int)\n",
    "\n",
    "print(train_df.groupby(f'fold_{n_folds}_seed_{seed}').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fbcfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>fold_5_seed_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0        30        43         0         0   \n",
       "3       0  ...         0         0         0         0         1         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  fold_5_seed_42  \n",
       "0         0         0         0               1  \n",
       "1         0         0         0               3  \n",
       "2         0         0         0               2  \n",
       "3         0         0         0               3  \n",
       "4         0         0         0               0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd418b",
   "metadata": {},
   "source": [
    "## Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c3dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[2:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = torch.cat((image, image, image), dim=0)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557fb72",
   "metadata": {},
   "source": [
    "## DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc6b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4a053",
   "metadata": {},
   "source": [
    "## MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac89401",
   "metadata": {},
   "source": [
    "### Tutorial on how to finetune torchvision pretrained models\n",
    "1. https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdc0e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'DenseNet',\n",
       " 'EfficientNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'RegNet',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'feature_extraction',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca14466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9164102",
   "metadata": {},
   "source": [
    "## Modify the linear layer of the model based on the customized use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce197eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = train_df['label'].nunique()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9959c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc = nn.Linear(512, num_labels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d37c8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ee2dc",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f450528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate metrics\n",
    "def get_metrics(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce36d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fold 1 -------------\n",
      "No.of samples in train data: (48000, 786)\n",
      "No.of samples in valid data: (12000, 786)\n",
      "TRAIN Dataset: 48000\n",
      "VALID Dataset: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_time : 7s - Val_time : <1s - Ep : 0 - Bi : 187 - Loss : 0.7904; 0.4592 - f1 : 0.7408; 0.8382\n",
      "Train_time : 6s - Val_time : <1s - Ep : 1 - Bi : 187 - Loss : 0.4533; 0.3739 - f1 : 0.8421; 0.8677\n",
      "Train_time : 6s - Val_time : <1s - Ep : 2 - Bi : 187 - Loss : 0.3856; 0.3387 - f1 : 0.8641; 0.8799\n",
      "Train_time : 6s - Val_time : <1s - Ep : 3 - Bi : 187 - Loss : 0.3436; 0.3171 - f1 : 0.8784; 0.8880\n",
      "Train_time : 6s - Val_time : <1s - Ep : 4 - Bi : 187 - Loss : 0.3140; 0.3030 - f1 : 0.8887; 0.8929\n",
      "------------- Fold 2 -------------\n",
      "No.of samples in train data: (48000, 786)\n",
      "No.of samples in valid data: (12000, 786)\n",
      "TRAIN Dataset: 48000\n",
      "VALID Dataset: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_time : 6s - Val_time : <1s - Ep : 0 - Bi : 187 - Loss : 0.3027; 0.2406 - f1 : 0.8929; 0.9137\n",
      "Train_time : 6s - Val_time : <1s - Ep : 1 - Bi : 187 - Loss : 0.2814; 0.2374 - f1 : 0.9008; 0.9124\n",
      "Train_time : 6s - Val_time : <1s - Ep : 2 - Bi : 187 - Loss : 0.2651; 0.2342 - f1 : 0.9053; 0.9159\n",
      "Train_time : 6s - Val_time : <1s - Ep : 3 - Bi : 187 - Loss : 0.2518; 0.2338 - f1 : 0.9106; 0.9151\n",
      "Train_time : 6s - Val_time : <1s - Ep : 4 - Bi : 187 - Loss : 0.2386; 0.2335 - f1 : 0.9146; 0.9147\n",
      "------------- Fold 3 -------------\n",
      "No.of samples in train data: (48000, 786)\n",
      "No.of samples in valid data: (12000, 786)\n",
      "TRAIN Dataset: 48000\n",
      "VALID Dataset: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_time : 6s - Val_time : <1s - Ep : 0 - Bi : 187 - Loss : 0.2366; 0.1724 - f1 : 0.9163; 0.9400\n",
      "Train_time : 6s - Val_time : <1s - Ep : 1 - Bi : 187 - Loss : 0.2253; 0.1721 - f1 : 0.9200; 0.9388\n",
      "Train_time : 6s - Val_time : <1s - Ep : 2 - Bi : 187 - Loss : 0.2103; 0.1716 - f1 : 0.9238; 0.9378\n",
      "Train_time : 6s - Val_time : <1s - Ep : 3 - Bi : 187 - Loss : 0.2037; 0.1744 - f1 : 0.9274; 0.9356\n",
      "Train_time : 6s - Val_time : <1s - Ep : 4 - Bi : 187 - Loss : 0.1935; 0.1732 - f1 : 0.9323; 0.9362\n",
      "------------- Fold 4 -------------\n",
      "No.of samples in train data: (48000, 786)\n",
      "No.of samples in valid data: (12000, 786)\n",
      "TRAIN Dataset: 48000\n",
      "VALID Dataset: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_time : 6s - Val_time : <1s - Ep : 0 - Bi : 187 - Loss : 0.1922; 0.1318 - f1 : 0.9310; 0.9542\n",
      "Train_time : 6s - Val_time : <1s - Ep : 1 - Bi : 187 - Loss : 0.1817; 0.1330 - f1 : 0.9354; 0.9523\n",
      "Train_time : 6s - Val_time : <1s - Ep : 2 - Bi : 187 - Loss : 0.1732; 0.1345 - f1 : 0.9383; 0.9521\n",
      "Train_time : 6s - Val_time : <1s - Ep : 3 - Bi : 187 - Loss : 0.1633; 0.1375 - f1 : 0.9406; 0.9514\n",
      "Train_time : 6s - Val_time : <1s - Ep : 4 - Bi : 187 - Loss : 0.1557; 0.1408 - f1 : 0.9449; 0.9485\n",
      "------------- Fold 5 -------------\n",
      "No.of samples in train data: (48000, 786)\n",
      "No.of samples in valid data: (12000, 786)\n",
      "TRAIN Dataset: 48000\n",
      "VALID Dataset: 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_time : 6s - Val_time : <1s - Ep : 0 - Bi : 187 - Loss : 0.1598; 0.0905 - f1 : 0.9419; 0.9717\n",
      "Train_time : 6s - Val_time : <1s - Ep : 1 - Bi : 187 - Loss : 0.1509; 0.0961 - f1 : 0.9461; 0.9680\n",
      "Train_time : 6s - Val_time : <1s - Ep : 2 - Bi : 187 - Loss : 0.1416; 0.0979 - f1 : 0.9489; 0.9674\n",
      "Train_time : 6s - Val_time : <1s - Ep : 3 - Bi : 187 - Loss : 0.1352; 0.1017 - f1 : 0.9519; 0.9641\n",
      "Train_time : 6s - Val_time : <1s - Ep : 4 - Bi : 187 - Loss : 0.1279; 0.1048 - f1 : 0.9554; 0.9633\n"
     ]
    }
   ],
   "source": [
    "for fold in range(n_folds):\n",
    "    print(f\"------------- Fold {fold+1} -------------\")\n",
    "\n",
    "    # TRAIN & VALID DATA\n",
    "    train_set = train_df[train_df[f'fold_{n_folds}_seed_{seed}'] != fold]\n",
    "    valid_set = train_df[train_df[f'fold_{n_folds}_seed_{seed}'] == fold]\n",
    "    \n",
    "#     train_set.drop(f'fold_{n_folds}_seed_{seed}', axis=1, inplace=True)\n",
    "#     valid_set.drop(f'fold_{n_folds}_seed_{seed}', axis=1, inplace=True)\n",
    "\n",
    "    print(f\"No.of samples in train data: {train_set.shape}\")\n",
    "    print(f\"No.of samples in valid data: {valid_set.shape}\")    \n",
    "\n",
    "    # DATASET\n",
    "    train_dataset = FashionDataset(train_set, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    valid_dataset = FashionDataset(valid_set, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "    print(f\"TRAIN Dataset: {train_dataset.__len__()}\")\n",
    "    print(f\"VALID Dataset: {valid_dataset.__len__()}\")\n",
    "    \n",
    "    # DATALOADER\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    mb = master_bar(range(5))\n",
    "    for epoch in mb:  \n",
    "        # ------------------------------------ Training loop ----------------------------------------\n",
    "        timer.add('train')\n",
    "        tr_loss, tr_f1_score, tr_steps = 0, 0, 0\n",
    "        for bi, d in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "            model.train()\n",
    "            images = d[0]\n",
    "            labels = d[1]\n",
    "\n",
    "            # load input data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = outputs\n",
    "            \n",
    "            loss = criterion(preds, labels)  \n",
    "            \n",
    "            logits = torch.argmax(torch.softmax(preds, dim=-1), dim=-1)\n",
    "            \n",
    "            labels = labels.to('cpu')\n",
    "            logits = logits.detach().to('cpu')\n",
    "\n",
    "            f1 = get_metrics(labels, logits)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            tr_f1_score += f1\n",
    "            \n",
    "            tr_steps += 1  \n",
    "\n",
    "            avg_tr_loss = tr_loss/tr_steps\n",
    "            avg_tr_f1_score = tr_f1_score/tr_steps\n",
    "            \n",
    "            mb.child.comment = 'tr_loss: {:.4f}; tr_f1_score: {:.4f}; avg_tr_loss: {:.4f}; avg_tr_f1_score: {:.4f}'.format(loss.item(), f1, avg_tr_loss, avg_tr_f1_score) \n",
    "        \n",
    "            ### calculate w1, w2, w3, ..... wn\n",
    "            loss.backward()\n",
    "            ### updates w1, w2, w3, ..... wn in the neural network\n",
    "            optimizer.step()\n",
    "            ### clears w1, w2, w3, ..... wn for the next iteration\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        tr_time = timer.fsince('train')\n",
    "        \n",
    "        # ------------------------------------------ Validation loop ---------------------------------------\n",
    "        timer.add('val')\n",
    "        vl_loss, vl_f1_score, vl_steps = 0, 0, 0\n",
    "        for bi, d in enumerate(progress_bar(valid_dataloader, parent=mb)):\n",
    "            model.eval()\n",
    "            images = d[0]\n",
    "            labels = d[1]\n",
    "\n",
    "            # load input data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = outputs\n",
    "            \n",
    "            loss = criterion(preds, labels)  \n",
    "            \n",
    "            logits = torch.argmax(torch.softmax(preds, dim=-1), dim=-1)\n",
    "            \n",
    "            labels = labels.to('cpu')\n",
    "            logits = logits.detach().to('cpu')\n",
    "\n",
    "            f1 = get_metrics(labels, logits)\n",
    "\n",
    "            vl_loss += loss.item()\n",
    "            vl_f1_score += f1\n",
    "            \n",
    "            vl_steps += 1  \n",
    "\n",
    "            avg_vl_loss = vl_loss/vl_steps\n",
    "            avg_vl_f1_score = vl_f1_score/vl_steps\n",
    "            \n",
    "            mb.child.comment = 'vl_loss: {:.4f}; vl_f1_score: {:.4f}; avg_vl_loss: {:.4f}; avg_vl_f1_score: {:.4f}'.format(loss.item(), f1, avg_vl_loss, avg_vl_f1_score) \n",
    "        \n",
    "        vl_time = timer.fsince('val')\n",
    "        \n",
    "        output = f\"Train_time : {tr_time} - Val_time : {vl_time} - Ep : {epoch} - Bi : {bi} - Loss : {avg_tr_loss:.4f}; {avg_vl_loss:.4f} - f1 : {avg_tr_f1_score:.4f}; {avg_vl_f1_score:.4f}\"\n",
    "        print(f\"{output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f705c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4107156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9b49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bef74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
